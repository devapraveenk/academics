{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fpdf\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: fpdf\n",
      "  Building wheel for fpdf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=ff4c45b8d0b7725c843bb68babdf164628ed0c7d2a3e575e8294cbb4398c2d95\n",
      "  Stored in directory: /Users/a2024/Library/Caches/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
      "Successfully built fpdf\n",
      "Installing collected packages: fpdf\n",
      "Successfully installed fpdf-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Assignment-1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting the code to handle special characters using utf-8 encoding\n",
    "\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Create instance of FPDF class\n",
    "pdf = FPDF()\n",
    "\n",
    "# Add a page\n",
    "pdf.add_page()\n",
    "\n",
    "# Set font for the document\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "# Title of the document\n",
    "pdf.set_font(\"Arial\", 'B', size=14)\n",
    "pdf.cell(200, 10, txt=\"CNN & Deep Learning - 2 Mark Questions\", ln=True, align='C')\n",
    "pdf.ln(10)\n",
    "\n",
    "# Questions and Answers\n",
    "content = [\n",
    "    (\"What is the purpose of Autoencoders?\", \n",
    "     \"1. Autoencoders are used to learn efficient data representations in an unsupervised manner. They compress the input into a smaller representation and then attempt to reconstruct the original data from this compressed form.\\n\"\n",
    "     \"2. Applications include image denoising, dimensionality reduction, and anomaly detection by learning patterns that best represent the data.\"),\n",
    "\n",
    "    (\"How does striding take place in CNN?\", \n",
    "     \"1. Stride determines how much the filter moves across the input matrix during convolution. A stride of 1 means the filter moves one pixel at a time, while a stride of 2 skips every other pixel.\\n\"\n",
    "     \"2. Striding helps control the output size; larger strides reduce the spatial dimensions of the output, leading to fewer computations and faster processing.\"),\n",
    "\n",
    "    (\"Define Convolution layer.\", \n",
    "     \"1. A convolution layer applies filters over the input data to detect specific features like edges, textures, and shapes. Each filter detects a different feature, which results in a set of feature maps.\\n\"\n",
    "     \"2. This layer reduces the number of parameters compared to fully connected layers due to local connections and weight sharing, making it ideal for image processing.\"),\n",
    "\n",
    "    (\"What are Restricted Boltzmann Machines?\", \n",
    "     \"1. RBMs are generative stochastic neural networks used to model the distribution of input data. They consist of a visible layer and a hidden layer with no connections within each layer.\\n\"\n",
    "     \"2. They are commonly used in dimensionality reduction, feature extraction, collaborative filtering, and building deep belief networks (DBNs).\"),\n",
    "\n",
    "    (\"Define Data Augmentation.\", \n",
    "     \"1. Data Augmentation artificially increases the training dataset by applying transformations such as flipping, rotation, cropping, or scaling to images, allowing models to generalize better.\\n\"\n",
    "     \"2. This technique helps reduce overfitting, especially when there is limited training data, by exposing the model to varied versions of the same data.\"),\n",
    "\n",
    "    (\"Define Convolution operation.\", \n",
    "     \"1. The convolution operation involves sliding a filter over the input data and performing element-wise multiplication followed by summation. This process extracts local features from the input.\\n\"\n",
    "     \"2. It helps in detecting various patterns, and different layers can detect increasingly complex patterns like edges in the first layer and objects in deeper layers.\"),\n",
    "\n",
    "    (\"Why do we prefer CNN over ANN for image data as input?\", \n",
    "     \"1. CNNs are specialized for image data because they use local connections (filters) to extract spatial features like edges and textures, unlike ANNs, which treat every pixel independently.\\n\"\n",
    "     \"2. CNNs also benefit from weight sharing, where the same filter is used across different regions of the image, reducing the number of parameters and computational requirements.\"),\n",
    "\n",
    "    (\"List out the different layers in CNN.\", \n",
    "     \"1. Convolution Layer: Extracts features from the input.\\n\"\n",
    "     \"2. Pooling Layer: Reduces the spatial dimensions of feature maps.\"),\n",
    "\n",
    "    (\"Why is pooling used in CNNs?\", \n",
    "     \"1. Pooling (such as max or average pooling) reduces the spatial size of the feature maps, which lowers computational complexity and helps reduce overfitting by providing an abstracted form of input.\\n\"\n",
    "     \"2. It also makes the model invariant to small translations, meaning minor shifts in the input wont affect the output significantly.\"),\n",
    "\n",
    "    (\"What did AlexNet bring to the world of deep learning?\", \n",
    "     \"1. AlexNet introduced the use of deep CNNs with multiple layers to improve image classification performance, significantly outperforming previous methods in the ImageNet competition.\\n\"\n",
    "     \"2. It also popularized techniques such as ReLU activation, dropout for regularization, and GPU acceleration to handle large-scale image datasets efficiently.\"),\n",
    "\n",
    "    (\"What problem does the ResNet architecture solve?\", \n",
    "     \"1. ResNet addresses the vanishing gradient problem, which makes training very deep networks difficult by adding residual connections that allow gradients to flow through the network more easily.\\n\"\n",
    "     \"2. It enables the training of deeper networks (e.g., 152 layers) without the degradation problem, where deeper networks often perform worse than shallower ones.\"),\n",
    "\n",
    "    (\"State the concept of ResNet.\", \n",
    "     \"1. ResNet (Residual Network) introduces shortcut connections between layers, allowing the model to learn residual functions instead of learning the entire transformation, making it easier to optimize.\\n\"\n",
    "     \"2. These skip connections ensure that deeper networks can still learn effectively, improving accuracy without the vanishing gradient issue.\"),\n",
    "\n",
    "    (\"What is stride in the context of CNNs?\", \n",
    "     \"1. Stride controls the step size of the filter movement over the input data during the convolution process. A stride of 2 moves the filter two pixels at a time, reducing the size of the output feature map.\\n\"\n",
    "     \"2. A larger stride results in downsampling of the input, reducing computational cost, while a smaller stride retains more detailed information in the output.\"),\n",
    "\n",
    "    (\"Draw the concept diagram of stacking.\", \n",
    "     \"[For diagram reference, refer to stacking in ensemble learning visual resources.]\\n\"\n",
    "     \"1. Stacking in machine learning involves training multiple models (base learners) and then using a meta-model (stacking model) to combine their predictions, improving overall accuracy.\"),\n",
    "\n",
    "    (\"Define stacking.\", \n",
    "     \"1. Stacking is an ensemble method that trains multiple base models on the same dataset and combines their outputs using a meta-model to make the final prediction, aiming to improve model performance.\\n\"\n",
    "     \"2. The meta-model learns from the predictions of the base models, usually reducing bias and variance for better generalization on unseen data.\"),\n",
    "\n",
    "    (\"What is the purpose of regularization in CNNs?\", \n",
    "     \"1. Regularization techniques like L2 regularization or dropout are used to penalize model complexity, preventing overfitting by encouraging simpler models that generalize better to unseen data.\\n\"\n",
    "     \"2. It helps in controlling the model's learning capacity and ensuring that it does not memorize the training data, thereby improving its ability to work with new data.\"),\n",
    "\n",
    "    (\"Why is ReLU used as an activation function in CNNs?\", \n",
    "     \"1. ReLU (Rectified Linear Unit) is computationally efficient and helps mitigate the vanishing gradient problem by allowing only positive values to pass through, thus maintaining gradient flow.\\n\"\n",
    "     \"2. It introduces non-linearity into the model, allowing CNNs to approximate complex functions and learn from the data more effectively.\"),\n",
    "\n",
    "    (\"What is the significance of depth (number of layers) in CNNs?\", \n",
    "     \"1. The depth of a CNN determines the complexity of patterns it can learn. Shallow networks may only detect simple features like edges, while deeper networks can learn more abstract features like object parts and entire objects.\\n\"\n",
    "     \"2. However, increasing depth also requires careful design to avoid problems like overfitting or vanishing gradients, often addressed by architectures like ResNet.\"),\n",
    "\n",
    "    (\"How does a convolutional layer differ from a fully connected layer?\", \n",
    "     \"1. A convolutional layer focuses on local spatial patterns in the input by applying filters over small regions, sharing the same weights across the input, reducing the number of parameters.\\n\"\n",
    "     \"2. A fully connected layer, in contrast, connects every neuron in the layer to all neurons in the previous layer, making it computationally expensive but useful for final decision-making.\"),\n",
    "\n",
    "    (\"What is parameter sharing in CNNs, and why is it important?\", \n",
    "     \"1. Parameter sharing refers to using the same set of filter weights across different regions of the input image. This reduces the number of parameters significantly, making CNNs efficient.\\n\"\n",
    "     \"2. It also ensures that the model detects features like edges or textures across the entire image, regardless of their position, leading to translation invariance.\")\n",
    "]\n",
    "\n",
    "# Adding questions and answers to PDF\n",
    "for question, answer in content:\n",
    "    # Question in bold\n",
    "    pdf.set_font(\"Arial\", 'B', 12)\n",
    "    pdf.multi_cell(0, 10, f\"{question}\")\n",
    "    \n",
    "    # Answer in regular font\n",
    "    pdf.set_font(\"Arial\", '', 12)\n",
    "    pdf.multi_cell(0, 10, f\"{answer}\")\n",
    "    pdf.ln(3)\n",
    "\n",
    "# Save the PDF\n",
    "output_path = \"../Assignment-1\"\n",
    "pdf.output(output_path)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Unit-3 2m.pdf'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "# Create instance of FPDF class\n",
    "pdf = FPDF()\n",
    "\n",
    "# Add a page\n",
    "pdf.add_page()\n",
    "\n",
    "# Set font for the document\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "# Title of the document\n",
    "pdf.set_font(\"Arial\", 'B', size=14)\n",
    "pdf.cell(200, 10, txt=\"Unit-3  2 Mark Questions\", ln=True, align='C')\n",
    "pdf.ln(10)\n",
    "\n",
    "# Questions and Answers content\n",
    "content = [\n",
    "    (\"What is the purpose of Autoencoders?\", \n",
    "     \"1. Autoencoders are used to learn efficient data representations in an unsupervised manner. They compress the input into a smaller representation and then attempt to reconstruct the original data from this compressed form.\\n\"\n",
    "     \"2. Applications include image denoising, dimensionality reduction, and anomaly detection by learning patterns that best represent the data.\"),\n",
    "\n",
    "    (\"How does striding take place in CNN?\", \n",
    "     \"1. Stride determines how much the filter moves across the input matrix during convolution. A stride of 1 means the filter moves one pixel at a time, while a stride of 2 skips every other pixel.\\n\"\n",
    "     \"2. Striding helps control the output size; larger strides reduce the spatial dimensions of the output, leading to fewer computations and faster processing.\"),\n",
    "\n",
    "    (\"Define Convolution layer.\", \n",
    "     \"1. A convolution layer applies filters over the input data to detect specific features like edges, textures, and shapes. Each filter detects a different feature, which results in a set of feature maps.\\n\"\n",
    "     \"2. This layer reduces the number of parameters compared to fully connected layers due to local connections and weight sharing, making it ideal for image processing.\"),\n",
    "\n",
    "    (\"What are Restricted Boltzmann Machines?\", \n",
    "     \"1. RBMs are generative stochastic neural networks used to model the distribution of input data. They consist of a visible layer and a hidden layer with no connections within each layer.\\n\"\n",
    "     \"2. They are commonly used in dimensionality reduction, feature extraction, collaborative filtering, and building deep belief networks (DBNs).\"),\n",
    "\n",
    "    (\"Define Data Augmentation.\", \n",
    "     \"1. Data Augmentation artificially increases the training dataset by applying transformations such as flipping, rotation, cropping, or scaling to images, allowing models to generalize better.\\n\"\n",
    "     \"2. This technique helps reduce overfitting, especially when there is limited training data, by exposing the model to varied versions of the same data.\"),\n",
    "\n",
    "    (\"Define Convolution operation.\", \n",
    "     \"1. The convolution operation involves sliding a filter over the input data and performing element-wise multiplication followed by summation. This process extracts local features from the input.\\n\"\n",
    "     \"2. It helps in detecting various patterns, and different layers can detect increasingly complex patterns like edges in the first layer and objects in deeper layers.\"),\n",
    "\n",
    "    (\"Why do we prefer CNN over ANN for image data as input?\", \n",
    "     \"1. CNNs are specialized for image data because they use local connections (filters) to extract spatial features like edges and textures, unlike ANNs, which treat every pixel independently.\\n\"\n",
    "     \"2. CNNs also benefit from weight sharing, where the same filter is used across different regions of the image, reducing the number of parameters and computational requirements.\"),\n",
    "\n",
    "    (\"List out the different layers in CNN.\", \n",
    "     \"1. Convolution Layer: Extracts features from the input.\\n\"\n",
    "     \"2. Pooling Layer: Reduces the spatial dimensions of feature maps.\"),\n",
    "\n",
    "    (\"Why is pooling used in CNNs?\", \n",
    "     \"1. Pooling (such as max or average pooling) reduces the spatial size of the feature maps, which lowers computational complexity and helps reduce overfitting by providing an abstracted form of input.\\n\"\n",
    "     \"2. It also makes the model invariant to small translations, meaning minor shifts in the input wont affect the output significantly.\"),\n",
    "\n",
    "    (\"What did AlexNet bring to the world of deep learning?\", \n",
    "     \"1. AlexNet introduced the use of deep CNNs with multiple layers to improve image classification performance, significantly outperforming previous methods in the ImageNet competition.\\n\"\n",
    "     \"2. It also popularized techniques such as ReLU activation, dropout for regularization, and GPU acceleration to handle large-scale image datasets efficiently.\"),\n",
    "\n",
    "    (\"What problem does the ResNet architecture solve?\", \n",
    "     \"1. ResNet addresses the vanishing gradient problem, which makes training very deep networks difficult by adding residual connections that allow gradients to flow through the network more easily.\\n\"\n",
    "     \"2. It enables the training of deeper networks (e.g., 152 layers) without the degradation problem, where deeper networks often perform worse than shallower ones.\"),\n",
    "\n",
    "    (\"State the concept of ResNet.\", \n",
    "     \"1. ResNet (Residual Network) introduces shortcut connections between layers, allowing the model to learn residual functions instead of learning the entire transformation, making it easier to optimize.\\n\"\n",
    "     \"2. These skip connections ensure that deeper networks can still learn effectively, improving accuracy without the vanishing gradient issue.\"),\n",
    "\n",
    "    (\"What is stride in the context of CNNs?\", \n",
    "     \"1. Stride controls the step size of the filter movement over the input data during the convolution process. A stride of 2 moves the filter two pixels at a time, reducing the size of the output feature map.\\n\"\n",
    "     \"2. A larger stride results in downsampling of the input, reducing computational cost, while a smaller stride retains more detailed information in the output.\"),\n",
    "\n",
    "    (\"Draw the concept diagram of stacking.\", \n",
    "     \"[For diagram reference, refer to stacking in ensemble learning visual resources.]\\n\"\n",
    "     \"1. Stacking in machine learning involves training multiple models (base learners) and then using a meta-model (stacking model) to combine their predictions, improving overall accuracy.\"),\n",
    "\n",
    "    (\"Define stacking.\", \n",
    "     \"1. Stacking is an ensemble method that trains multiple base models on the same dataset and combines their outputs using a meta-model to make the final prediction, aiming to improve model performance.\\n\"\n",
    "     \"2. The meta-model learns from the predictions of the base models, usually reducing bias and variance for better generalization on unseen data.\"),\n",
    "\n",
    "    (\"What is the purpose of regularization in CNNs?\", \n",
    "     \"1. Regularization techniques like L2 regularization or dropout are used to penalize model complexity, preventing overfitting by encouraging simpler models that generalize better to unseen data.\\n\"\n",
    "     \"2. It helps in controlling the model's learning capacity and ensuring that it does not memorize the training data, thereby improving its ability to work with new data.\"),\n",
    "\n",
    "    (\"Why is ReLU used as an activation function in CNNs?\", \n",
    "     \"1. ReLU (Rectified Linear Unit) is computationally efficient and helps mitigate the vanishing gradient problem by allowing only positive values to pass through, thus maintaining gradient flow.\\n\"\n",
    "     \"2. It introduces non-linearity into the model, allowing CNNs to approximate complex functions and learn from the data more effectively.\"),\n",
    "\n",
    "    (\"What is the significance of depth (number of layers) in CNNs?\", \n",
    "     \"1. The depth of a CNN determines the complexity of patterns it can learn. Shallow networks may only detect simple features like edges, while deeper networks can learn more abstract features like object parts and entire objects.\\n\"\n",
    "     \"2. However, increasing depth also requires careful design to avoid problems like overfitting or vanishing gradients, often addressed by architectures like ResNet.\"),\n",
    "\n",
    "    (\"How does a convolutional layer differ from a fully connected layer?\", \n",
    "     \"1. A convolutional layer focuses on local spatial patterns in the input by applying filters over small regions, sharing the same weights across the input, reducing the number of parameters.\\n\"\n",
    "     \"2. A fully connected layer, in contrast, connects every neuron in the layer to all neurons in the previous layer, making it computationally expensive but useful for final decision-making.\"),\n",
    "\n",
    "    (\"What is parameter sharing in CNNs, and why is it important?\", \n",
    "     \"1. Parameter sharing refers to using the same set of filter weights across different regions of the input image. This reduces the number of parameters significantly, making CNNs efficient.\\n\"\n",
    "     \"2. It also ensures that the model detects features like edges or textures across the entire image, regardless of their position, leading to translation invariance.\")\n",
    "]\n",
    "\n",
    "# Adding questions and answers to PDF\n",
    "for question, answer in content:\n",
    "    # Question in bold\n",
    "    pdf.set_font(\"Arial\", 'B', 12)\n",
    "    pdf.multi_cell(0, 10, question.encode('utf-8').decode('utf-8'))\n",
    "    \n",
    "    # Answer in regular font\n",
    "    pdf.set_font(\"Arial\", '', 12)\n",
    "    pdf.multi_cell(0, 10, answer.encode('utf-8').decode('utf-8'))\n",
    "    pdf.ln(3)\n",
    "\n",
    "# Save the PDF with the correct file extension\n",
    "output_path = \"../Unit-3 2m.pdf\"\n",
    "pdf.output(output_path)\n",
    "\n",
    "# Output the path for reference\n",
    "output_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
